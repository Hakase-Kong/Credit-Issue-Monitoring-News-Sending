import os
import streamlit as st
import pandas as pd
from io import BytesIO
import requests
import re
from datetime import datetime
import telepot
from openai import OpenAI
import newspaper  # newspaper3k
from difflib import SequenceMatcher

# --- CSS ìŠ¤íƒ€ì¼ ---
st.markdown("""
<style>
[data-testid="column"] > div { gap: 0rem !important; }
.stMultiSelect [data-baseweb="tag"] { background-color: #ff5c5c !important; color: white !important; border: none !important; font-weight: bold; }
.sentiment-badge { display: inline-block; padding: 0.08em 0.6em; margin-left: 0.2em; border-radius: 0.8em; font-size: 0.85em; font-weight: bold; vertical-align: middle; }
.sentiment-positive { background: #2ecc40; color: #fff; }
.sentiment-negative { background: #ff4136; color: #fff; }
.stBox { background: #fcfcfc; border-radius: 0.7em; border: 1.5px solid #e0e2e6; margin-bottom: 1.2em; padding: 1.1em 1.2em 1.2em 1.2em; box-shadow: 0 2px 8px 0 rgba(0,0,0,0.03); }
.flex-row-bottom { display: flex; align-items: flex-end; gap: 0.5rem; margin-bottom: 0.5rem; }
.flex-grow { flex: 1 1 0%; }
.flex-btn { min-width: 90px; }
</style>
""", unsafe_allow_html=True)

# --- ì œì™¸ í‚¤ì›Œë“œ ---
EXCLUDE_TITLE_KEYWORDS = [
    "ì•¼êµ¬", "ì¶•êµ¬", "ë°°êµ¬", "ë†êµ¬", "ê³¨í”„", "eìŠ¤í¬ì¸ ", "ì˜¬ë¦¼í”½", "ì›”ë“œì»µ", "Kë¦¬ê·¸", "í”„ë¡œì•¼êµ¬", "í”„ë¡œì¶•êµ¬", "í”„ë¡œë°°êµ¬", "í”„ë¡œë†êµ¬",
    "ë¶€ê³ ", "ì¸ì‚¬", "ìŠ¹ì§„", "ì„ëª…", "ë°œë ¹", "ì¸ì‚¬ë°œë ¹", "ì¸ì‚¬ì´ë™",
    "ë¸Œëœë“œí‰íŒ", "ë¸Œëœë“œ í‰íŒ", "ë¸Œëœë“œ ìˆœìœ„", "ë¸Œëœë“œì§€ìˆ˜",
    "ì½”ìŠ¤í”¼", "ì½”ìŠ¤ë‹¥", "ì£¼ê°€", "ì£¼ì‹", "ì¦ì‹œ", "ì‹œì„¸", "ë§ˆê°", "ì¥ì¤‘", "ì¥ë§ˆê°", "ê±°ë˜ëŸ‰", "ê±°ë˜ëŒ€ê¸ˆ", "ìƒí•œê°€", "í•˜í•œê°€"
]

def exclude_by_title_keywords(title, exclude_keywords):
    for word in exclude_keywords:
        if word in title:
            return True
    return False

# --- ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™” ---
if "favorite_keywords" not in st.session_state:
    st.session_state.favorite_keywords = set()
if "search_results" not in st.session_state:
    st.session_state.search_results = {}
if "show_limit" not in st.session_state:
    st.session_state.show_limit = {}
if "search_triggered" not in st.session_state:
    st.session_state.search_triggered = False
if "selected_articles" not in st.session_state:
    st.session_state.selected_articles = []

# --- ì¦ê²¨ì°¾ê¸° ì¹´í…Œê³ ë¦¬(ë³€ê²½ ê¸ˆì§€) ---
favorite_categories = {
    "êµ­/ê³µì±„": [],
    "ê³µê³µê¸°ê´€": [],
    "ë³´í—˜ì‚¬": ["í˜„ëŒ€í•´ìƒ", "ë†í˜‘ìƒëª…", "ë©”ë¦¬ì¸ í™”ì¬", "êµë³´ìƒëª…", "ì‚¼ì„±í™”ì¬", "ì‚¼ì„±ìƒëª…", "ì‹ í•œë¼ì´í”„", "í¥êµ­ìƒëª…", "ë™ì–‘ìƒëª…", "ë¯¸ë˜ì—ì…‹ìƒëª…"],
    "5ëŒ€ê¸ˆìœµì§€ì£¼": ["ì‹ í•œê¸ˆìœµ", "í•˜ë‚˜ê¸ˆìœµ", "KBê¸ˆìœµ", "ë†í˜‘ê¸ˆìœµ", "ìš°ë¦¬ê¸ˆìœµ"],
    "5ëŒ€ì‹œì¤‘ì€í–‰": ["ë†í˜‘ì€í–‰", "êµ­ë¯¼ì€í–‰", "ì‹ í•œì€í–‰", "ìš°ë¦¬ì€í–‰", "í•˜ë‚˜ì€í–‰"],
    "ì¹´ë“œì‚¬": ["KBêµ­ë¯¼ì¹´ë“œ", "í˜„ëŒ€ì¹´ë“œ", "ì‹ í•œì¹´ë“œ", "ë¹„ì”¨ì¹´ë“œ", "ì‚¼ì„±ì¹´ë“œ"],
    "ìºí”¼íƒˆ": ["í•œêµ­ìºí”¼íƒˆ", "í˜„ëŒ€ìºí”¼íƒˆ"],
    "ì§€ì£¼ì‚¬": ["SKì´ë…¸ë² ì´ì…˜", "GSì—ë„ˆì§€", "SK", "GS"],
    "ì—ë„ˆì§€": ["SKê°€ìŠ¤", "GSì¹¼í…ìŠ¤", "S-Oil", "SKì—ë„ˆì§€", "SKì•¤ë¬´ë¸Œ", "ì½”ë¦¬ì•„ì—ë„ˆì§€í„°ë¯¸ë„"],
    "ë°œì „": ["GSíŒŒì›Œ", "GSEPS", "ì‚¼ì²œë¦¬"],
    "ìë™ì°¨": ["LGì—ë„ˆì§€ì†”ë£¨ì…˜", "í•œì˜¨ì‹œìŠ¤í…œ", "í¬ìŠ¤ì½”í“¨ì²˜ì— ", "í•œêµ­íƒ€ì´ì–´"],
    "ì „ê¸°/ì „ì": ["SKí•˜ì´ë‹‰ìŠ¤", "LGì´ë…¸í…", "LGì „ì", "LSì¼ë ‰íŠ¸ë¦­"],
    "ì†Œë¹„ì¬": ["ì´ë§ˆíŠ¸", "LF", "CJì œì¼ì œë‹¹", "SKë„¤íŠ¸ì›ìŠ¤", "CJëŒ€í•œí†µìš´"],
    "ë¹„ì² /ì² ê°•": ["í¬ìŠ¤ì½”", "í˜„ëŒ€ì œì² ", "ê³ ë ¤ì•„ì—°"],
    "ì„ìœ í™”í•™": ["LGí™”í•™", "SKì§€ì˜¤ì„¼íŠ¸ë¦­"],
    "ê±´ì„¤": ["í¬ìŠ¤ì½”ì´ì•¤ì”¨"],
    "íŠ¹ìˆ˜ì±„": ["ì£¼íƒë„ì‹œë³´ì¦ê³µì‚¬", "ê¸°ì—…ì€í–‰"]
}

excel_company_categories = {
    "êµ­/ê³µì±„": [],
    "ê³µê³µê¸°ê´€": [],
    "ë³´í—˜ì‚¬": [
        "í˜„ëŒ€í•´ìƒí™”ì¬ë³´í—˜(í›„)", "ë†í˜‘ìƒëª…ë³´í—˜(í›„)", "ë©”ë¦¬ì¸ í™”ì¬í•´ìƒë³´í—˜(í›„)", "êµë³´ìƒëª…(í›„)",
        "ì‚¼ì„±í™”ì¬", "ì‚¼ì„±ìƒëª…", "ì‹ í•œë¼ì´í”„(í›„)", "í¥êµ­ìƒëª…ë³´í—˜(í›„)", "ë™ì–‘ìƒëª…ë³´í—˜(í›„)", "ë¯¸ë˜ì—ì…‹ìƒëª…(í›„)"
    ],
    "5ëŒ€ê¸ˆìœµì§€ì£¼": [
        "ì‹ í•œì§€ì£¼", "í•˜ë‚˜ê¸ˆìœµì§€ì£¼", "KBê¸ˆìœµ", "ë†í˜‘ê¸ˆìœµì§€ì£¼", "ìš°ë¦¬ê¸ˆìœµì§€ì£¼"
    ],
    "5ëŒ€ì‹œì¤‘ì€í–‰": [
        "ë†í˜‘ì€í–‰", "êµ­ë¯¼ì€í–‰", "ì‹ í•œì€í–‰", "ìš°ë¦¬ì€í–‰", "í•˜ë‚˜ì€í–‰"
    ],
    "ì¹´ë“œì‚¬": [
        "ì¼€ì´ë¹„ì¹´ë“œ", "í˜„ëŒ€ì¹´ë“œ", "ì‹ í•œì¹´ë“œ", "ë¹„ì”¨ì¹´ë“œ", "ì‚¼ì„±ì¹´ë“œ"
    ],
    "ìºí”¼íƒˆ": [
        "í•œêµ­ìºí”¼íƒˆ", "í˜„ëŒ€ìºí”¼íƒˆ"
    ],
    "ì§€ì£¼ì‚¬": [
        "SKì´ë…¸ë² ì´ì…˜", "ì§€ì—ìŠ¤ì—ë„ˆì§€", "SK", "GS"
    ],
    "ì—ë„ˆì§€": [
        "SKê°€ìŠ¤", "GSì¹¼í…ìŠ¤", "S-Oil", "SKì—ë„ˆì§€", "ì—ìŠ¤ì¼€ì´ì—”ë¬´ë¸Œ", "ì½”ë¦¬ì•„ì—ë„ˆì§€í„°ë¯¸ë„"
    ],
    "ë°œì „": [
        "GSíŒŒì›Œ", "ì§€ì—ìŠ¤ì´í”¼ì—ìŠ¤", "ì‚¼ì²œë¦¬"
    ],
    "ìë™ì°¨": [
        "LGì—ë„ˆì§€ì†”ë£¨ì…˜", "í•œì˜¨ì‹œìŠ¤í…œ", "í¬ìŠ¤ì½”í“¨ì²˜ì— ", "í•œêµ­íƒ€ì´ì–´ì•¤í…Œí¬ë†€ë¡œì§€"
    ],
    "ì „ê¸°/ì „ì": [
        "SKí•˜ì´ë‹‰ìŠ¤", "LGì´ë…¸í…", "LGì „ì", "ì—˜ì—ìŠ¤ì¼ë ‰íŠ¸ë¦­"
    ],
    "ì†Œë¹„ì¬": [
        "ì´ë§ˆíŠ¸", "LF", "CJì œì¼ì œë‹¹", "SKë„¤íŠ¸ì›ìŠ¤", "CJëŒ€í•œí†µìš´"
    ],
    "ë¹„ì² /ì² ê°•": [
        "í¬ìŠ¤ì½”", "í˜„ëŒ€ì œì² ", "ê³ ë ¤ì•„ì—°"
    ],
    "ì„ìœ í™”í•™": [
        "LGí™”í•™", "SKì§€ì˜¤ì„¼íŠ¸ë¦­"
    ],
    "ê±´ì„¤": [
        "í¬ìŠ¤ì½”ì´ì•¤ì”¨"
    ],
    "íŠ¹ìˆ˜ì±„": [
        "ì£¼íƒë„ì‹œë³´ì¦ê³µì‚¬", "ê¸°ì—…ì€í–‰"
    ]
}

# --- ê³µí†µ í•„í„° ì˜µì…˜(ëŒ€ë¶„ë¥˜/ì†Œë¶„ë¥˜ ì—†ì´ ëª¨ë‘ ì ìš©) ---
common_filter_categories = {
    "ì‹ ìš©/ë“±ê¸‰": [
        "ì‹ ìš©ë“±ê¸‰", "ë“±ê¸‰ì „ë§", "í•˜ë½", "ê°•ë“±", "í•˜í–¥", "ìƒí–¥", "ë””í´íŠ¸", "ë¶€ì‹¤", "ë¶€ë„", "ë¯¸ì§€ê¸‰", "ìˆ˜ìš” ë¯¸ë‹¬", "ë¯¸ë§¤ê°", "ì œë„ ê°œí¸", "EOD"
    ],
    "ìˆ˜ìš”/ê³µê¸‰": [
        "ìˆ˜ìš”", "ê³µê¸‰", "ìˆ˜ê¸‰", "ë‘”í™”", "ìœ„ì¶•", "ì„±ì¥", "ê¸‰ë“±", "ê¸‰ë½", "ìƒìŠ¹", "í•˜ë½", "ë¶€ì§„", "ì‹¬í™”"
    ],
    "ì‹¤ì /ì¬ë¬´": [
        "ì‹¤ì ", "ë§¤ì¶œ", "ì˜ì—…ì´ìµ", "ì ì", "ì†ì‹¤", "ë¹„ìš©", "ë¶€ì±„ë¹„ìœ¨", "ì´ìë³´ìƒë°°ìœ¨"
    ],
    "ìê¸ˆ/ì¡°ë‹¬": [
        "ì°¨ì…", "ì¡°ë‹¬", "ì„¤ë¹„íˆ¬ì", "íšŒì‚¬ì±„", "ë°œí–‰", "ì¸ìˆ˜", "ë§¤ê°"
    ],
    "êµ¬ì¡°/ì¡°ì •": [
        "M&A", "í•©ë³‘", "ê³„ì—´ ë¶„ë¦¬", "êµ¬ì¡°ì¡°ì •", "ë‹¤ê°í™”", "êµ¬ì¡° ì¬í¸"
    ],
    "ê±°ì‹œ/ì •ì±…": [
        "ê¸ˆë¦¬", "í™˜ìœ¨", "ê´€ì„¸", "ë¬´ì—­ì œì¬", "ë³´ì¡°ê¸ˆ", "ì„¸ì•¡ ê³µì œ", "ê²½ìŸ"
    ],
    "ì§€ë°°êµ¬ì¡°/ë²•": [
        "íš¡ë ¹", "ë°°ì„", "ê³µì •ê±°ë˜", "ì˜¤ë„ˆë¦¬ìŠ¤í¬", "ëŒ€ì£¼ì£¼", "ì§€ë°°êµ¬ì¡°"
    ]
}
ALL_COMMON_FILTER_KEYWORDS = []
for keywords in common_filter_categories.values():
    ALL_COMMON_FILTER_KEYWORDS.extend(keywords)

# --- ì‚°ì—…ë³„ í•„í„° ì˜µì…˜ ---
industry_filter_categories = {
    "ì€í–‰ ë° ê¸ˆìœµì§€ì£¼": [
        "ê²½ì˜ì‹¤íƒœí‰ê°€", "BIS", "CET1", "ìë³¸ë¹„ìœ¨", "ìƒê°í˜• ì¡°ê±´ë¶€ìë³¸ì¦ê¶Œ", "ìë³¸í™•ì¶©", "ìë³¸ì—¬ë ¥", "ìë³¸ì ì •ì„±", "LCR",
        "ì¡°ë‹¬ê¸ˆë¦¬", "NIM", "ìˆœì´ìë§ˆì§„", "ê³ ì •ì´í•˜ì—¬ì‹ ë¹„ìœ¨", "ëŒ€ì†ì¶©ë‹¹ê¸ˆ", "ì¶©ë‹¹ê¸ˆ", "ë¶€ì‹¤ì±„ê¶Œ", "ì—°ì²´ìœ¨", "ê°€ê³„ëŒ€ì¶œ", "ì·¨ì•½ì°¨ì£¼"
    ],
    "ë³´í—˜ì‚¬": [
        "ë³´ì¥ì„±ë³´í—˜", "ì €ì¶•ì„±ë³´í—˜", "ë³€ì•¡ë³´í—˜", "í‡´ì§ì—°ê¸ˆ", "ì¼ë°˜ë³´í—˜", "ìë™ì°¨ë³´í—˜", "ALM", "ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨", "K-ICS",
        "ë³´í—˜ìˆ˜ìµì„±", "ë³´í—˜ì†ìµ", "ìˆ˜ì…ë³´í—˜ë£Œ", "CSM", "ìƒê°", "íˆ¬ìì†ìµ", "ìš´ìš©ì„±ê³¼", "IFRS4", "IFRS17", "ë³´í—˜ë¶€ì±„",
        "ì¥ê¸°ì„ ë„ê¸ˆë¦¬", "ìµœì¢…ê´€ì°°ë§Œê¸°", "ìœ ë™ì„± í”„ë¦¬ë¯¸ì—„", "ì‹ ì¢…ìë³¸ì¦ê¶Œ", "í›„ìˆœìœ„ì±„", "ìœ„í—˜ìì‚°ë¹„ì¤‘", "ê°€ì¤‘ë¶€ì‹¤ìì‚°ë¹„ìœ¨"
    ],
    "ì¹´ë“œì‚¬": [
        "ë¯¼ê°„ì†Œë¹„ì§€í‘œ", "ëŒ€ì†ì¤€ë¹„ê¸ˆ", "ê°€ê³„ë¶€ì±„", "ì—°ì²´ìœ¨", "ê°€ë§¹ì ì¹´ë“œìˆ˜ìˆ˜ë£Œ", "ëŒ€ì¶œì„±ìì‚°", "ì‹ ìš©íŒë§¤ìì‚°", "ê³ ì •ì´í•˜ì—¬ì‹ ", "ë ˆë²„ë¦¬ì§€ë°°ìœ¨",
        "ê±´ì „ì„±", "ì¼€ì´ë±…í¬", "ì´íƒˆ"
    ],
    "ìºí”¼íƒˆ": [
        "ì¶©ë‹¹ê¸ˆì»¤ë²„ë¦¬ì§€ë¹„ìœ¨", "ê³ ì •ì´í•˜ì—¬ì‹ ", "PFêµ¬ì¡°ì¡°ì •", "ë¦¬ìŠ¤ìì‚°", "ì†ì‹¤í¡ìˆ˜ëŠ¥ë ¥", "ë¶€ë™ì‚°PFì—°ì²´ì±„ê¶Œ", "ìì‚°í¬íŠ¸í´ë¦¬ì˜¤", "ê±´ì „ì„±",
        "ì¡°ì •ì´ìì‚°ìˆ˜ìµë¥ ", "êµ°ì¸ê³µì œíšŒ"
    ],
    "ì§€ì£¼ì‚¬": [
        "SKì§€ì˜¤ì„¼íŠ¸ë¦­", "SKì—ë„ˆì§€", "SKì—”ë¬´ë¸Œ", "SKì¸ì²œì„ìœ í™”í•™", "GSì¹¼í…ìŠ¤", "GSíŒŒì›Œ", "SKì´ë…¸ë² ì´ì…˜", "SKí…”ë ˆì½¤", "SKì˜¨",
        "GSì—ë„ˆì§€", "GSë¦¬í…Œì¼", "GS E&C", "2ì°¨ì „ì§€", "ì„ìœ í™”í•™", "ìœ¤í™œìœ ", "ì „ê¸°ì°¨", "ë°°í„°ë¦¬", "ì •ìœ ", "ì´ë™í†µì‹ "
    ],
    "ì—ë„ˆì§€": [
        "ì •ìœ ", "ìœ ê°€", "ì •ì œë§ˆì§„", "ìŠ¤í”„ë ˆë“œ", "ê°€ë™ë¥ ", "ì¬ê³  ì†ì‹¤", "ì¤‘êµ­ ìˆ˜ìš”", "IMO ê·œì œ", "ì €ìœ í™© ì—°ë£Œ", "LNG",
        "í„°ë¯¸ë„", "ìœ¤í™œìœ "
    ],
    "ë°œì „": [
        "LNG", "ì²œì—°ê°€ìŠ¤", "ìœ ê°€", "SMP", "REC", "ê³„í†µì‹œì¥", "íƒ„ì†Œì„¸", "íƒ„ì†Œë°°ì¶œê¶Œ", "ì „ë ¥ì‹œì¥ ê°œí¸", "ì „ë ¥ ììœ¨í™”",
        "ê°€ë™ë¥ ", "ë„ì‹œê°€ìŠ¤"
    ],
    "ìë™ì°¨": [
        "AMPC ë³´ì¡°ê¸ˆ", "IRA ì¸ì„¼í‹°ë¸Œ", "ì¤‘êµ­ ë°°í„°ë¦¬", "EV ìˆ˜ìš”", "ì „ê¸°ì°¨", "ESSìˆ˜ìš”", "ë¦¬íŠ¬", "íƒ€ì´ì–´"
    ],
    "ì „ê¸°ì „ì": [
        "CHIPS ë³´ì¡°ê¸ˆ", "ì¤‘êµ­", "DRAM", "HBM", "ê´‘í• ì†”ë£¨ì…˜", "ì•„ì´í°", "HVAC", "HVTR"
    ],
    "ì² ê°•": [
        "ì² ê´‘ì„", "í›„íŒ", "ê°•íŒ", "ì² ê·¼", "ìŠ¤í”„ë ˆë“œ", "ì² ê°•", "ê°€ë™ë¥ ", "ì œì² ì†Œ", "ì…§ë‹¤ìš´", "ì¤‘êµ­ì‚° ì €ê°€",
        "ì¤‘êµ­ ìˆ˜ì¶œ ê°ì†Œ", "ê±´ì„¤ê²½ê¸°", "ì¡°ì„  ìˆ˜ìš”", "íŒŒì—…"
    ],
    "ë¹„ì² ": [
        "ì—°", "ì•„ì—°", "ë‹ˆì¼ˆ", "ì•ˆí‹°ëª¨ë‹ˆ", "ê²½ì˜ê¶Œ ë¶„ìŸ", "MBK", "ì˜í’"
    ],
    "ì†Œë§¤": [
        "ë‚´ìˆ˜ë¶€ì§„", "ì‹œì¥ì§€ë°°ë ¥", "SKí…”ë ˆì½¤", "SKë§¤ì§", "CLS", "HMR", "ë¼ì´ì‹ ", "ì•„ë¯¸ë…¸ì‚°", "ìŠˆì™„ìŠ¤ì»´í¼ë‹ˆ",
        "ì˜ë¥˜", "ì‹ ì„¸ê³„", "ëŒ€í˜•ë§ˆíŠ¸ ì˜ë¬´íœ´ì—…", "Gë§ˆì¼“", "Wì»¨ì…‰", "ìŠ¤íƒ€í•„ë“œ"
    ],
    "ì„ìœ í™”í•™": [
        "ì„ìœ í™”í•™", "ì„í™”", "ìœ ê°€", "ì¦ì„¤", "ìŠ¤í”„ë ˆë“œ", "ê°€ë™ë¥ ", "PX", "ë²¤ì  ", "ì¤‘êµ­ ì¦ì„¤", "ì¤‘ë™ COTC",
        "LGì—ë„ˆì§€ì†”ë£¨ì…˜", "ì „ê¸°ì°¨", "ë°°í„°ë¦¬", "ë¦¬íŠ¬", "IRA", "AMPC"
    ],
    "ê±´ì„¤": [
        "ì² ê·¼ ê°€ê²©", "ì‹œë©˜íŠ¸ ê°€ê²©", "ê³µì‚¬ë¹„", "SOC ì˜ˆì‚°", "ë„ì‹œì •ë¹„ ì§€ì›", "ìš°ë°œì±„ë¬´", "ìˆ˜ì£¼", "ì£¼ê°„ì‚¬", "ì‚¬ê³ ",
        "ì‹œê³µëŠ¥ë ¥ìˆœìœ„", "ë¯¸ë¶„ì–‘", "ëŒ€ì†ì¶©ë‹¹ê¸ˆ"
    ],
    "íŠ¹ìˆ˜ì±„": [
        "ìë³¸í™•ì¶©", "HUG", "ì „ì„¸ì‚¬ê¸°", "ë³´ì¦ì‚¬ê³ ", "ë³´ì¦ë£Œìœ¨", "íšŒìˆ˜ìœ¨", "ë³´ì¦ì”ì•¡", "ëŒ€ìœ„ë³€ì œì•¡",
        "ì¤‘ì†Œê¸°ì—…ëŒ€ì¶œ", "ëŒ€ì†ì¶©ë‹¹ê¸ˆ", "ë¶€ì‹¤ì±„ê¶Œ", "ë¶ˆë²•", "êµ¬ì†"
    ]
}

# --- ì¤‘ë³µ ê¸°ì‚¬ ì œê±° í•¨ìˆ˜ ---
def normalize_title(title):
    title = re.sub(r"[^\w\s]", "", title)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    title = re.sub(r"\s+", " ", title)     # ë‹¤ì¤‘ ê³µë°± â†’ 1ê°œ
    return title.strip().lower()

def is_similar_title(title1, title2, threshold=0.75):
    t1 = normalize_title(title1)
    t2 = normalize_title(title2)
    ratio = SequenceMatcher(None, t1, t2).ratio()
    return ratio > threshold

def remove_duplicate_articles(articles):
    seen = set()
    unique_articles = []
    for article in articles:
        link = article.get("link")
        if link and link not in seen:
            unique_articles.append(article)
            seen.add(link)
    return unique_articles

def remove_duplicate_articles_by_title(articles, threshold=0.75):
    unique_articles = []
    for article in articles:
        title = article.get("title", "")
        if not any(is_similar_title(title, a.get("title", ""), threshold) for a in unique_articles):
            unique_articles.append(article)
    return unique_articles

def deduplicate_articles(articles, title_threshold=0.75):
    articles = remove_duplicate_articles(articles)
    articles = remove_duplicate_articles_by_title(articles, threshold=title_threshold)
    return articles

# --- ì´í•˜ ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼ ---
# (fetch_naver_news, fetch_gnews_news, ê¸°íƒ€ í•¨ìˆ˜ë“¤ì€ ê·¸ëŒ€ë¡œ ë‘ì‹œë©´ ë©ë‹ˆë‹¤)
# ì•„ë˜ì™€ ê°™ì´ ì¤‘ë³µ ì œê±° í•¨ìˆ˜ê°€ ì ìš©ëœ ë¶€ë¶„ë§Œ ë°”ê¿”ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.

# ... (ì¤‘ëµ: ê¸°ì¡´ ì½”ë“œ ë™ì¼)

def process_keywords(keyword_list, start_date, end_date, require_keyword_in_title=False):
    for k in keyword_list:
        if is_english(k):
            articles = fetch_gnews_news(k, start_date, end_date, require_keyword_in_title=require_keyword_in_title)
        else:
            articles = fetch_naver_news(k, start_date, end_date, require_keyword_in_title=require_keyword_in_title)
        # ë§í¬+ì œëª©ìœ ì‚¬ë„ ì¤‘ë³µ ì œê±°
        articles = deduplicate_articles(articles, title_threshold=0.75)
        st.session_state.search_results[k] = articles
        if k not in st.session_state.show_limit:
            st.session_state.show_limit[k] = 5

def render_articles_with_single_summary_and_telegram(results, show_limit, show_sentiment_badge=True, enable_summary=True):
    SENTIMENT_CLASS = {
        "ê¸ì •": "sentiment-positive",
        "ë¶€ì •": "sentiment-negative"
    }

    if "article_checked" not in st.session_state:
        st.session_state.article_checked = {}

    col_list, col_summary = st.columns([1, 1])

    with col_list:
        st.markdown("### ê¸°ì‚¬ ìš”ì•½ ê²°ê³¼")
        for keyword, articles in results.items():
            # ë§í¬+ì œëª©ìœ ì‚¬ë„ ì¤‘ë³µ ì œê±° (ë Œë”ë§ ì§ì „)
            articles = deduplicate_articles(articles, title_threshold=0.75)
            with st.container(border=True):
                st.markdown(f"**[{keyword}]**")
                limit = st.session_state.show_limit.get(keyword, 5)
                for idx, article in enumerate(articles[:limit]):
                    unique_id = re.sub(r'\W+', '', article['link'])[-16:]
                    key = f"{keyword}_{idx}_{unique_id}"
                    cache_key = f"summary_{key}"
                    if show_sentiment_badge:
                        if cache_key not in st.session_state:
                            one_line, summary, sentiment, full_text = summarize_article_from_url(
                                article['link'], article['title'], do_summary=enable_summary
                            )
                            st.session_state[cache_key] = (one_line, summary, sentiment, full_text)
                        else:
                            one_line, summary, sentiment, full_text = st.session_state[cache_key]
                        sentiment_label = sentiment if sentiment else "ë¶„ì„ì¤‘"
                        sentiment_class = SENTIMENT_CLASS.get(sentiment_label, "sentiment-negative")
                        md_line = (
                            f"[{article['title']}]({article['link']}) "
                            f"<span class='sentiment-badge {sentiment_class}'>({sentiment_label})</span> "
                            f"{article['date']} | {article['source']}"
                        )
                    else:
                        md_line = (
                            f"[{article['title']}]({article['link']}) "
                            f"{article['date']} | {article['source']}"
                        )
                    cols = st.columns([0.04, 0.96])
                    with cols[0]:
                        checked = st.checkbox("", value=st.session_state.article_checked.get(key, False), key=f"news_{key}")
                    with cols[1]:
                        st.markdown(md_line, unsafe_allow_html=True)
                    st.session_state.article_checked[key] = checked

                if limit < len(articles):
                    if st.button("ë”ë³´ê¸°", key=f"more_{keyword}"):
                        st.session_state.show_limit[keyword] += 10
                        st.rerun()

    with col_summary:
        st.markdown("### ì„ íƒëœ ê¸°ì‚¬ ìš”ì•½/ê°ì„±ë¶„ì„")
        with st.container(border=True):
            selected_articles = []
            def safe_title_for_append(val):
                if val is None or str(val).strip() == "" or str(val).lower() == "nan" or str(val) == "0":
                    return "ì œëª©ì—†ìŒ"
                return str(val)
            for keyword, articles in results.items():
                articles = remove_duplicate_articles(articles)
                limit = st.session_state.show_limit.get(keyword, 5)
                for idx, article in enumerate(articles[:limit]):
                    unique_id = re.sub(r'\W+', '', article['link'])[-16:]
                    key = f"{keyword}_{idx}_{unique_id}"
                    cache_key = f"summary_{key}"
                    if st.session_state.article_checked.get(key, False):
                        if cache_key in st.session_state:
                            one_line, summary, sentiment, full_text = st.session_state[cache_key]
                        else:
                            one_line, summary, sentiment, full_text = summarize_article_from_url(
                                article['link'], article['title'], do_summary=enable_summary
                            )
                            st.session_state[cache_key] = (one_line, summary, sentiment, full_text)
                        selected_articles.append({
                            "í‚¤ì›Œë“œ": keyword,
                            "ê¸°ì‚¬ì œëª©": safe_title_for_append(article.get('title')),
                            "ìš”ì•½": one_line,
                            "ìš”ì•½ë³¸": summary,
                            "ê°ì„±": sentiment,
                            "ë§í¬": article['link'],
                            "ë‚ ì§œ": article['date'],
                            "ì¶œì²˜": article['source']
                        })
                        if show_sentiment_badge:
                            st.markdown(
                                f"#### [{article['title']}]({article['link']}) "
                                f"<span class='sentiment-badge {SENTIMENT_CLASS.get(sentiment, 'sentiment-negative')}'>({sentiment})</span>",
                                unsafe_allow_html=True
                            )
                        else:
                            st.markdown(f"#### [{article['title']}]({article['link']})", unsafe_allow_html=True)
                        st.markdown(f"- **ë‚ ì§œ/ì¶œì²˜:** {article['date']} | {article['source']}")
                        if enable_summary:
                            st.markdown(f"- **í•œ ì¤„ ìš”ì•½:** {one_line}")
                        st.markdown(f"- **ê°ì„±ë¶„ì„:** `{sentiment}`")
                        st.markdown("---")

            st.session_state.selected_articles = selected_articles
            st.write(f"ì„ íƒëœ ê¸°ì‚¬ ê°œìˆ˜: {len(selected_articles)}")

            excel_company_order = []
            for cat in ["êµ­/ê³µì±„", "ê³µê³µê¸°ê´€", "ë³´í—˜ì‚¬", "5ëŒ€ê¸ˆìœµì§€ì£¼", "5ëŒ€ì‹œì¤‘ì€í–‰", "ì¹´ë“œì‚¬", "ìºí”¼íƒˆ", "ì§€ì£¼ì‚¬", "ì—ë„ˆì§€", "ë°œì „", "ìë™ì°¨", "ì „ê¸°/ì „ì", "ì†Œë¹„ì¬", "ë¹„ì² /ì² ê°•", "ì„ìœ í™”í•™", "ê±´ì„¤", "íŠ¹ìˆ˜ì±„"]:
                excel_company_order.extend(excel_company_categories.get(cat, []))

            if st.session_state.selected_articles:
                excel_bytes = get_excel_download_with_favorite_and_excel_company_col(
                    st.session_state.selected_articles,
                    favorite_categories,
                    excel_company_categories
                )
                st.download_button(
                    label="ğŸ“¥ ë§ì¶¤ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                    data=excel_bytes.getvalue(),
                    file_name="ë‰´ìŠ¤ìš”ì•½_ë§ì¶¤í˜•.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

if st.session_state.search_results:
    filtered_results = {}
    for keyword, articles in st.session_state.search_results.items():
        filtered_articles = [a for a in articles if article_passes_all_filters(a)]
        if filtered_articles:
            filtered_results[keyword] = filtered_articles
    render_articles_with_single_summary_and_telegram(
        filtered_results,
        st.session_state.show_limit,
        show_sentiment_badge=st.session_state.get("show_sentiment_badge", False),
        enable_summary=st.session_state.get("enable_summary", True)
    )
